{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44328d25",
   "metadata": {},
   "source": [
    "# Elastic Rank Eval Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9749c1",
   "metadata": {},
   "source": [
    "## Install Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c409e5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -q -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421faf3",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7907e8e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "- Finding elastic/elasticstack versions matching \"~> 0.12\"...\n",
      "- Finding elastic/ec versions matching \"~> 0.12\"...\n",
      "- Using previously-installed elastic/ec v0.12.2\n",
      "- Using previously-installed elastic/elasticstack v0.12.2\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n",
      "\n",
      "Terraform used the selected providers to generate the following execution\n",
      "plan. Resource actions are indicated with the following symbols:\n",
      "  \u001b[32m+\u001b[0m create\u001b[0m\n",
      "\n",
      "Terraform will perform the following actions:\n",
      "\n",
      "\u001b[1m  # ec_elasticsearch_project.demo_project\u001b[0m will be created\n",
      "\u001b[0m  \u001b[32m+\u001b[0m\u001b[0m resource \"ec_elasticsearch_project\" \"demo_project\" {\n",
      "      \u001b[32m+\u001b[0m\u001b[0m alias         = (known after apply)\n",
      "      \u001b[32m+\u001b[0m\u001b[0m cloud_id      = (known after apply)\n",
      "      \u001b[32m+\u001b[0m\u001b[0m credentials   = (known after apply)\n",
      "      \u001b[32m+\u001b[0m\u001b[0m endpoints     = (known after apply)\n",
      "      \u001b[32m+\u001b[0m\u001b[0m id            = (known after apply)\n",
      "      \u001b[32m+\u001b[0m\u001b[0m metadata      = (known after apply)\n",
      "      \u001b[32m+\u001b[0m\u001b[0m name          = \"demo_project\"\n",
      "      \u001b[32m+\u001b[0m\u001b[0m optimized_for = \"general_purpose\"\n",
      "      \u001b[32m+\u001b[0m\u001b[0m region_id     = \"gcp-us-central1\"\n",
      "      \u001b[32m+\u001b[0m\u001b[0m search_lake   = {\n",
      "          \u001b[32m+\u001b[0m\u001b[0m boost_window = (known after apply)\n",
      "          \u001b[32m+\u001b[0m\u001b[0m search_power = 2000\n",
      "        }\n",
      "      \u001b[32m+\u001b[0m\u001b[0m type          = (known after apply)\n",
      "    }\n",
      "\n",
      "\u001b[1mPlan:\u001b[0m \u001b[0m1 to add, 0 to change, 0 to destroy.\n",
      "\n",
      "Changes to Outputs:\n",
      "  \u001b[32m+\u001b[0m\u001b[0m elastic_cloud_id = (known after apply)\n",
      "  \u001b[32m+\u001b[0m\u001b[0m elastic_password = (sensitive value)\n",
      "  \u001b[32m+\u001b[0m\u001b[0m elastic_username = (known after apply)\n",
      "  \u001b[32m+\u001b[0m\u001b[0m gemini_api_key   = (sensitive value)\n",
      "  \u001b[32m+\u001b[0m\u001b[0m jina_api_key     = (sensitive value)\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Creating...\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [00m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [00m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [00m30s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [00m40s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [00m50s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [01m00s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [01m10s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Still creating... [01m20s elapsed]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Creation complete after 1m24s [id=cb5446332b244e8ba93e1bb274f764a8]\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 1 added, 0 changed, 0 destroyed.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Outputs:\n",
      "\n",
      "\u001b[0melastic_cloud_id = \"demo_project:dXMtY2VudHJhbDEuZ2NwLmVsYXN0aWMuY2xvdWQkY2I1NDQ2MzMyYjI0NGU4YmE5M2UxYmIyNzRmNzY0YTguZXMkY2I1NDQ2MzMyYjI0NGU4YmE5M2UxYmIyNzRmNzY0YTgua2I=\"\n",
      "elastic_password = <sensitive>\n",
      "elastic_username = \"admin\"\n",
      "gemini_api_key = <sensitive>\n",
      "jina_api_key = <sensitive>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "terraform -chdir=terraform init  -upgrade\n",
    "terraform -chdir=terraform apply -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d50fb",
   "metadata": {},
   "source": [
    "## Create Environment File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "072fd6e5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > .env << EOF\n",
    "ELASTIC_USERNAME=$(terraform -chdir=terraform output elastic_username)\n",
    "ELASTIC_PASSWORD=$(terraform -chdir=terraform output elastic_password)\n",
    "ELASTIC_CLOUD_ID=$(terraform -chdir=terraform output elastic_cloud_id)\n",
    "JINA_API_KEY=$(terraform -chdir=terraform output jina_api_key)\n",
    "GEMINI_API_KEY=$(terraform -chdir=terraform output gemini_api_key)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703a1b9",
   "metadata": {},
   "source": [
    "# Create Document and Judgment Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a25de0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Sample Generated Document ***\n",
      "{\n",
      "  \"_id\": 1,\n",
      "  \"title\": \"Modern Pedagogy and Effective Student Learning Strategies\",\n",
      "  \"content\": \"In the realm of modern education, effective pedagogy requires a deep understanding of how students process information. Teachers must design a curriculum that not only delivers academic knowledge but also fosters critical thinking skills through rigorous assessment and tailored instruction.\"\n",
      "}\n",
      "\n",
      "*** Sample Generated Judgment ***\n",
      "{\n",
      "  \"query_text\": \"assessment strategies for student learning\",\n",
      "  \"_index\": \"test-index\",\n",
      "  \"_id\": \"3\",\n",
      "  \"rating\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "import random\n",
    "import json\n",
    "\n",
    "MODEL = \"gemini-3-pro-preview\"\n",
    "TERM_SETS = [\n",
    "    [\"algorithm\", \"data\", \"system\", \"network\", \"software\", \"hardware\", \"security\", \"optimization\", \"automation\", \"scalability\", \"performance\", \"integration\"],\n",
    "    [\"patient\", \"treatment\", \"diagnosis\", \"clinical\", \"therapeutic\", \"medical\", \"healthcare\", \"wellness\", \"prevention\", \"symptoms\", \"recovery\", \"medicine\"],\n",
    "    [\"investment\", \"portfolio\", \"returns\", \"risk\", \"capital\", \"market\", \"assets\", \"revenue\", \"profit\", \"liquidity\", \"valuation\", \"dividend\"],\n",
    "    [\"learning\", \"students\", \"curriculum\", \"teaching\", \"assessment\", \"pedagogy\", \"education\", \"training\", \"skills\", \"knowledge\", \"academic\", \"instruction\"],\n",
    "    [\"environmental\", \"sustainable\", \"renewable\", \"emissions\", \"conservation\", \"ecosystem\", \"climate\", \"green\", \"carbon\", \"pollution\", \"biodiversity\"]\n",
    "]\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def generate_documents(term_set):\n",
    "    prompt = f\"\"\"\n",
    "    - You are an expert JSON generator. Your task is to strictly adhere to the user's prompt and the provided JSON schema to generate a valid array of JSON objects.\n",
    "    - Generate 100 unique JSON documents\n",
    "    - The first 50 documents should utilize the following terms in a grammatically correct manner in the title and content fields: {term_set}\n",
    "    - The remaining 50 documents should be on random topics.  Those topics could use some of the provided terms.\n",
    "    - Each document should have a unique integer id starting from 1.\n",
    "    - The title should be concise, between 5 to 10 words.\n",
    "    - The content should be a detailed paragraph of at least 30 words.\n",
    "    - Don't put any bolding, asterisks or quotation marks in the output.\n",
    "    - Generate the documents such that there is a mix of relevance values when performing lexical or\n",
    "    semantic search on them with the given terms.\n",
    "    \"\"\"\n",
    "\n",
    "    class Document(BaseModel):\n",
    "        id: int = Field(alias=\"_id\", description=\"The unique identifier of the document.\")\n",
    "        title: str = Field(description=\"The title of the document.\")\n",
    "        content: str = Field(description=\"The content of the document.\")\n",
    "        model_config = ConfigDict(\n",
    "            populate_by_name=True,\n",
    "        )\n",
    "\n",
    "    class DocumentList(BaseModel):\n",
    "        documents: list[Document] = Field(description=\"A list of generated documents.\")\n",
    "\n",
    "    client = genai.Client()\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=prompt,\n",
    "        config={\n",
    "            \"tools\":[],\n",
    "            \"response_mime_type\":\"application/json\",\n",
    "            \"response_schema\": DocumentList.model_json_schema(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result_list = DocumentList.model_validate_json(response.text)\n",
    "    return [doc.model_dump(by_alias=True) for doc in result_list.documents]\n",
    "\n",
    "\n",
    "def generate_judgments(term_set, docs):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert search relevance rater. Your task is to generate 1 search query\n",
    "    and 20 relevance judgments from the provided documents based on that query.\n",
    "    - The search query should be concise, between 3 to 7 words, and utilize some of the following terms: {term_set}.\n",
    "    - These search query should be selected such that it has varying degrees of relevance to the \n",
    "    provided documents in both lexical and semantic terms.\n",
    "    - The relevance judgments should be based on how relevant each document is to the query.\n",
    "    - Relevance is rated on a scale from 1 (least relevant/match) to 5 (perfect match).\n",
    "    - Consider both lexical and semantic relevance when rating the documents.\n",
    "    - The index field should be the value 'test-index' for all judgments.\n",
    "    - The id field should correspond to the document id being rated.\n",
    "\n",
    "    **Documents to Rate Against:**\n",
    "    {docs[0:50]}\n",
    "\n",
    "    Generate the judgment list in the required JSON schema.\n",
    "    \"\"\"\n",
    "\n",
    "    class Judgment(BaseModel):\n",
    "        query_text: str = Field(description=\"The search query text.\")\n",
    "        index: str = Field(alias=\"_index\", description=\"The name of the index being queried.\")\n",
    "        id: str = Field(alias=\"_id\", description=\"The unique identifier of the document.\")\n",
    "        rating: int = Field(description=\"The relevance score of the document.\")\n",
    "\n",
    "    class JudgmentList(BaseModel):\n",
    "        judgments: list[Judgment] = Field(description=\"A list of generated relevance judgments.\")\n",
    "\n",
    "    client = genai.Client()\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=prompt,\n",
    "        config={\n",
    "            \"tools\":[],\n",
    "            \"response_mime_type\":\"application/json\",\n",
    "            \"response_schema\": JudgmentList.model_json_schema(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result_list = JudgmentList.model_validate_json(response.text)\n",
    "    return [judgment.model_dump(by_alias=True) for judgment in result_list.judgments]\n",
    "\n",
    "if not os.path.exists(\"documents.jsonl\") or not os.path.exists(\"judgments.jsonl\"):\n",
    "    term_set = random.choice(TERM_SETS)\n",
    "\n",
    "    documents = generate_documents(term_set)\n",
    "    with open(\"documents.jsonl\", \"w\") as f:\n",
    "        for doc in documents:\n",
    "            f.write(json.dumps(doc) + \"\\n\")\n",
    "\n",
    "    judgments = generate_judgments(term_set,documents)\n",
    "    with open(\"judgments.jsonl\", \"w\") as f:\n",
    "        for judgment in judgments:\n",
    "            f.write(json.dumps(judgment) + \"\\n\")\n",
    "\n",
    "with open(\"documents.jsonl\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    print(\"*** Sample Generated Document ***\")\n",
    "    print(json.dumps(json.loads(line), indent=2))\n",
    "\n",
    "with open(\"judgments.jsonl\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    print(\"\\n*** Sample Generated Judgment ***\")\n",
    "    print(json.dumps(json.loads(line), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbf67d",
   "metadata": {},
   "source": [
    "# Create Jina Reranker Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b370f320",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inference_id': 'jina-reranker-v3', 'task_type': 'rerank', 'service': 'jinaai', 'service_settings': {'model_id': 'jina-reranker-v3', 'rate_limit': {'requests_per_minute': 2000}}, 'task_settings': {'top_n': 10, 'return_documents': True}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(cloud_id=os.getenv(\"ELASTIC_CLOUD_ID\"), \n",
    "    request_timeout=160,\n",
    "    basic_auth=(os.getenv(\"ELASTIC_USERNAME\"), \n",
    "    os.getenv(\"ELASTIC_PASSWORD\"))\n",
    ")\n",
    "\n",
    "es.options(ignore_status=[404]).inference.delete(inference_id=\"jina-reranker-v3\")\n",
    "response = es.inference.put(\n",
    "    task_type=\"rerank\",\n",
    "    inference_id=\"jina-reranker-v3\",\n",
    "    body={\n",
    "        \"service\": \"jinaai\",\n",
    "        \"service_settings\": {\n",
    "            \"api_key\": os.getenv(\"JINA_API_KEY\"),\n",
    "            \"model_id\": \"jina-reranker-v3\"\n",
    "        }, \n",
    "        \"task_settings\": {\n",
    "            \"top_n\": 10,\n",
    "            \"return_documents\": True\n",
    "        } \n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4691c2",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e7b451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 documents indexed\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "import json\n",
    "\n",
    "INDEX_NAME = \"test-index\"\n",
    "mappings = {\n",
    "    \"properties\": {\n",
    "        \"title\": {\n",
    "            \"type\": \"text\",\n",
    "            \"fields\": {\n",
    "                \"keyword\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"content\": {\n",
    "            \"type\": \"text\",\n",
    "            \"fields\": {\n",
    "                \"embedding\": {\n",
    "                    \"type\": \"semantic_text\",\n",
    "                    \"inference_id\": \".elser-2-elastic\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}            \n",
    "\n",
    "es.options(ignore_status=[404]).indices.delete(index=INDEX_NAME)\n",
    "es.indices.create(index=INDEX_NAME, body={\"mappings\": mappings})\n",
    "\n",
    "def gen_data():\n",
    "    with open(\"documents.jsonl\", \"r\") as f:\n",
    "        for line in f:    \n",
    "            yield json.loads(line.strip())\n",
    "            \n",
    "result = bulk(client=es, index=INDEX_NAME, actions=gen_data())\n",
    "print(result[0], \"documents indexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee988ee",
   "metadata": {},
   "source": [
    "# Create Query Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95cc527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Lexical Eval Template ***\n",
      "{\n",
      "  \"id\": \"lexical_query_template\",\n",
      "  \"template\": {\n",
      "    \"source\": {\n",
      "      \"size\": 10,\n",
      "      \"retriever\": {\n",
      "        \"standard\": {\n",
      "          \"query\": {\n",
      "            \"multi_match\": {\n",
      "              \"query\": \"{{query_string}}\",\n",
      "              \"fields\": [\n",
      "                \"title\",\n",
      "                \"content\"\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "*** Semantic Eval Template ***\n",
      "{\n",
      "  \"id\": \"semantic_query_template\",\n",
      "  \"template\": {\n",
      "    \"source\": {\n",
      "      \"size\": 10,\n",
      "      \"retriever\": {\n",
      "        \"standard\": {\n",
      "          \"query\": {\n",
      "            \"match\": {\n",
      "              \"content.embedding\": {\n",
      "                \"query\": \"{{query_string}}\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "*** Rescore Eval Template ***\n",
      "{\n",
      "  \"id\": \"rescore_query_template\",\n",
      "  \"template\": {\n",
      "    \"source\": {\n",
      "      \"size\": 10,\n",
      "      \"retriever\": {\n",
      "        \"rescorer\": {\n",
      "          \"rescore\": {\n",
      "            \"window_size\": 10,\n",
      "            \"query\": {\n",
      "              \"rescore_query\": {\n",
      "                \"dis_max\": {\n",
      "                  \"queries\": [\n",
      "                    {\n",
      "                      \"match_phrase\": {\n",
      "                        \"title\": {\n",
      "                          \"query\": \"{{query_string}}\",\n",
      "                          \"boost\": 10.0,\n",
      "                          \"slop\": 15\n",
      "                        }\n",
      "                      }\n",
      "                    },\n",
      "                    {\n",
      "                      \"multi_match\": {\n",
      "                        \"query\": \"{{query_string}}\",\n",
      "                        \"fields\": [\n",
      "                          \"title\",\n",
      "                          \"content^2\"\n",
      "                        ]\n",
      "                      }\n",
      "                    },\n",
      "                    {\n",
      "                      \"match_phrase\": {\n",
      "                        \"content\": {\n",
      "                          \"query\": \"{{query_string}}\",\n",
      "                          \"boost\": 3.0,\n",
      "                          \"slop\": 15\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  ],\n",
      "                  \"tie_breaker\": 0.3\n",
      "                }\n",
      "              },\n",
      "              \"query_weight\": 1,\n",
      "              \"rescore_query_weight\": 1.0\n",
      "            }\n",
      "          },\n",
      "          \"retriever\": {\n",
      "            \"linear\": {\n",
      "              \"retrievers\": [\n",
      "                {\n",
      "                  \"retriever\": {\n",
      "                    \"standard\": {\n",
      "                      \"query\": {\n",
      "                        \"multi_match\": {\n",
      "                          \"query\": \"{{query_string}}\",\n",
      "                          \"fields\": [\n",
      "                            \"title\",\n",
      "                            \"content\"\n",
      "                          ]\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"weight\": 0.3\n",
      "                },\n",
      "                {\n",
      "                  \"retriever\": {\n",
      "                    \"standard\": {\n",
      "                      \"query\": {\n",
      "                        \"match\": {\n",
      "                          \"content.embedding\": {\n",
      "                            \"query\": \"{{query_string}}\"\n",
      "                          }\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"weight\": 0.7\n",
      "                }\n",
      "              ],\n",
      "              \"normalizer\": \"l2_norm\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "*** RRF Eval Template ***\n",
      "{\n",
      "  \"id\": \"rrf_query_template\",\n",
      "  \"template\": {\n",
      "    \"source\": {\n",
      "      \"size\": 10,\n",
      "      \"retriever\": {\n",
      "        \"rrf\": {\n",
      "          \"rank_window_size\": 10,\n",
      "          \"retrievers\": [\n",
      "            {\n",
      "              \"retriever\": {\n",
      "                \"standard\": {\n",
      "                  \"query\": {\n",
      "                    \"multi_match\": {\n",
      "                      \"query\": \"{{query_string}}\",\n",
      "                      \"fields\": [\n",
      "                        \"title\",\n",
      "                        \"content\"\n",
      "                      ]\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"weight\": 0.25\n",
      "            },\n",
      "            {\n",
      "              \"retriever\": {\n",
      "                \"standard\": {\n",
      "                  \"query\": {\n",
      "                    \"match\": {\n",
      "                      \"content.embedding\": {\n",
      "                        \"query\": \"{{query_string}}\"\n",
      "                      }\n",
      "                    }\n",
      "                  }\n",
      "                }\n",
      "              },\n",
      "              \"weight\": 0.75\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "*** Rerank Eval Template ***\n",
      "{\n",
      "  \"id\": \"rerank_query_template\",\n",
      "  \"template\": {\n",
      "    \"source\": {\n",
      "      \"size\": 10,\n",
      "      \"retriever\": {\n",
      "        \"text_similarity_reranker\": {\n",
      "          \"retriever\": {\n",
      "            \"rrf\": {\n",
      "              \"rank_window_size\": 10,\n",
      "              \"retrievers\": [\n",
      "                {\n",
      "                  \"retriever\": {\n",
      "                    \"standard\": {\n",
      "                      \"query\": {\n",
      "                        \"multi_match\": {\n",
      "                          \"query\": \"{{query_string}}\",\n",
      "                          \"fields\": [\n",
      "                            \"title\",\n",
      "                            \"content\"\n",
      "                          ]\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"weight\": 0.25\n",
      "                },\n",
      "                {\n",
      "                  \"retriever\": {\n",
      "                    \"standard\": {\n",
      "                      \"query\": {\n",
      "                        \"match\": {\n",
      "                          \"content.embedding\": {\n",
      "                            \"query\": \"{{query_string}}\"\n",
      "                          }\n",
      "                        }\n",
      "                      }\n",
      "                    }\n",
      "                  },\n",
      "                  \"weight\": 0.75\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          },\n",
      "          \"field\": \"content\",\n",
      "          \"inference_id\": \"jina-reranker-v3\",\n",
      "          \"inference_text\": \"{{query_string}}\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ratings = []\n",
    "query_string = \"\"\n",
    "with open(\"judgments.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line.strip())\n",
    "        query_string = obj[\"query_text\"]\n",
    "        del obj[\"query_text\"]\n",
    "        ratings.append(obj)\n",
    "\n",
    "# Lexical Query - BM25\n",
    "lexical_retriever = {\n",
    "    \"standard\": {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": \"{{query_string}}\",\n",
    "                \"fields\": [\"title\", \"content\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "lexical_query_template = {\n",
    "    \"id\": \"lexical_query_template\",\n",
    "    \"template\": {\n",
    "        \"source\": {\n",
    "            \"size\": 10,\n",
    "            \"retriever\": lexical_retriever\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "lexical_request =  {\n",
    "    \"id\": \"lexical_query\",\n",
    "    \"ratings\": ratings,\n",
    "    \"template_id\": \"lexical_query_template\",\n",
    "    \"params\": {\n",
    "        \"query_string\": query_string\n",
    "    }\n",
    "}\n",
    "\n",
    "# Semantic Query - ELSER on GPU\n",
    "semantic_retriever = {\n",
    "    \"standard\": {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"content.embedding\": {\n",
    "                    \"query\": \"{{query_string}}\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "semantic_query_template = {\n",
    "    \"id\": \"semantic_query_template\",\n",
    "    \"template\": {\n",
    "        \"source\": {\n",
    "            \"size\": 10,\n",
    "            \"retriever\": semantic_retriever\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "semantic_request = {\n",
    "    \"id\": \"semantic_query\",\n",
    "    \"ratings\": ratings,\n",
    "    \"template_id\": \"semantic_query_template\",\n",
    "    \"params\": {\n",
    "        \"query_string\": query_string\n",
    "    }\n",
    "}\n",
    "\n",
    "# Rescore Query - Linear + Rescorer\n",
    "linear_retriever = {\n",
    "    \"linear\": {\n",
    "        \"retrievers\": [\n",
    "            {\n",
    "                \"retriever\": lexical_retriever,\n",
    "                \"weight\": 0.3\n",
    "            }, \n",
    "            {\n",
    "                \"retriever\": semantic_retriever,   \n",
    "                \"weight\": 0.7   \n",
    "            }\n",
    "        ],\n",
    "        \"normalizer\": \"l2_norm\"\n",
    "    }\n",
    "}\n",
    "\n",
    "rescore_retriever = {\n",
    "    \"rescorer\": {\n",
    "        \"rescore\": {\n",
    "            \"window_size\": 10,\n",
    "            \"query\": {\n",
    "                \"rescore_query\": {\n",
    "                    \"dis_max\": {\n",
    "                        \"queries\": [\n",
    "                            {\n",
    "                                \"match_phrase\": {\n",
    "                                    \"title\": {\n",
    "                                        \"query\": \"{{query_string}}\",\n",
    "                                        \"boost\": 10.0,\n",
    "                                        \"slop\": 15\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                                \"multi_match\": {\n",
    "                                    \"query\": \"{{query_string}}\",\n",
    "                                    \"fields\": [\"title\", \"content^2\"]\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                                \"match_phrase\": {\n",
    "                                    \"content\": {\n",
    "                                        \"query\": \"{{query_string}}\",\n",
    "                                        \"boost\": 3.0,\n",
    "                                        \"slop\": 15\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"tie_breaker\": 0.3\n",
    "                    }\n",
    "                },\n",
    "                \"query_weight\": 1,\n",
    "                \"rescore_query_weight\": 1.0\n",
    "            }\n",
    "        },\n",
    "        \"retriever\": linear_retriever\n",
    "    }\n",
    "}\n",
    "\n",
    "rescore_query_template = {\n",
    "    \"id\": \"rescore_query_template\",\n",
    "    \"template\": {\n",
    "        \"source\": {\n",
    "            \"size\": 10,\n",
    "            \"retriever\": rescore_retriever\n",
    "        }\n",
    "    }\n",
    "}\n",
    "  \n",
    "rescore_request = {\n",
    "    \"id\": \"rescore_query\",\n",
    "    \"ratings\": ratings,\n",
    "    \"template_id\": \"rescore_query_template\",\n",
    "    \"params\": {\n",
    "        \"query_string\": query_string\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hybrid Query - Weighted RRF\n",
    "rrf_retriever = {\n",
    "    \"rrf\": {\n",
    "        \"rank_window_size\": 10,\n",
    "        \"retrievers\": [\n",
    "            {\n",
    "                \"retriever\": lexical_retriever,\n",
    "                \"weight\": .25\n",
    "            }, \n",
    "            {\n",
    "                \"retriever\": semantic_retriever,\n",
    "                \"weight\": .75\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "rrf_query_template = {\n",
    "    \"id\": \"rrf_query_template\",\n",
    "    \"template\": {\n",
    "        \"source\": {\n",
    "            \"size\": 10,\n",
    "            \"retriever\": rrf_retriever\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "rrf_request = {\n",
    "    \"id\": \"rrf_query\",\n",
    "    \"ratings\": ratings,\n",
    "    \"template_id\": \"rrf_query_template\",\n",
    "    \"params\": {\n",
    "        \"query_string\": query_string\n",
    "    }\n",
    "}\n",
    "\n",
    "# Rerank Query - Weighted RRF + Jina Reranker\n",
    "rerank_retriever = {\n",
    "    \"text_similarity_reranker\": {\n",
    "        \"retriever\": rrf_retriever,\n",
    "        \"field\": \"content\",\n",
    "        \"inference_id\": \"jina-reranker-v3\",\n",
    "        \"inference_text\": \"{{query_string}}\"\n",
    "    }\n",
    "}\n",
    "    \n",
    "rerank_query_template = {\n",
    "    \"id\": \"rerank_query_template\",\n",
    "    \"template\": {\n",
    "        \"source\": {\n",
    "            \"size\": 10,\n",
    "            \"retriever\": rerank_retriever\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "rerank_request = {\n",
    "    \"id\": \"rerank_query\",\n",
    "    \"ratings\": ratings,\n",
    "    \"template_id\": \"rerank_query_template\",\n",
    "    \"params\": {\n",
    "        \"query_string\": query_string\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"*** Lexical Eval Template ***\")\n",
    "print(json.dumps(lexical_query_template, indent=2))\n",
    "\n",
    "print(\"\\n*** Semantic Eval Template ***\")\n",
    "print(json.dumps(semantic_query_template, indent=2))\n",
    "\n",
    "print(\"\\n*** Rescore Eval Template ***\")\n",
    "print(json.dumps(rescore_query_template, indent=2))\n",
    "\n",
    "print(\"\\n*** RRF Eval Template ***\")\n",
    "print(json.dumps(rrf_query_template, indent=2))\n",
    "\n",
    "print(\"\\n*** Rerank Eval Template ***\")\n",
    "print(json.dumps(rerank_query_template, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce5989",
   "metadata": {},
   "source": [
    "# Execute Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36bcfbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG</th>\n",
       "      <th>ERR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lexical</th>\n",
       "      <td>0.443</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Semantic</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rescore</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RRF</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rerank</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NDCG    ERR\n",
       "Lexical   0.443  0.471\n",
       "Semantic  0.910  0.984\n",
       "Rescore   0.742  0.605\n",
       "RRF       0.833  0.980\n",
       "Rerank    0.822  0.979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "templates = [lexical_query_template, semantic_query_template, rrf_query_template, rerank_query_template, rescore_query_template]\n",
    "requests = [lexical_request, semantic_request, rrf_request, rerank_request, rescore_request]\n",
    "metrics = [\n",
    "    {\"dcg\": {\"k\": 10, \"normalize\": True}},\n",
    "    {\"expected_reciprocal_rank\": {\"k\": 10, \"maximum_relevance\": 5}},\n",
    "]\n",
    "results = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    metric_name = list(metric.keys())[0]\n",
    "    eval = {\n",
    "        \"templates\": templates,\n",
    "        \"requests\": requests,\n",
    "        \"metric\": metric\n",
    "    }\n",
    "    result = es.rank_eval(body=eval, index=INDEX_NAME)\n",
    "    for query in result['details']:\n",
    "        if metric_name not in results:\n",
    "            results[metric_name] = {}\n",
    "        results[metric_name][query] = result['details'][query]['metric_score']\n",
    "\n",
    "df = pd.DataFrame(results).round(3)\n",
    "df.rename(columns={'dcg': 'NDCG', 'expected_reciprocal_rank': 'ERR'}, inplace=True)\n",
    "df.rename(index={'lexical_query': 'Lexical', 'semantic_query': 'Semantic', 'rrf_query': 'RRF', 'rerank_query': 'Rerank', 'rescore_query': 'Rescore'}, inplace=True)\n",
    "df = df.reindex(['Lexical', 'Semantic', 'Rescore', 'RRF', 'Rerank'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45932b0",
   "metadata": {},
   "source": [
    "## Destroy Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7b95ab6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Refreshing state... [id=cb5446332b244e8ba93e1bb274f764a8]\u001b[0m\n",
      "\n",
      "Terraform used the selected providers to generate the following execution\n",
      "plan. Resource actions are indicated with the following symbols:\n",
      "  \u001b[31m-\u001b[0m destroy\u001b[0m\n",
      "\n",
      "Terraform will perform the following actions:\n",
      "\n",
      "\u001b[1m  # ec_elasticsearch_project.demo_project\u001b[0m will be \u001b[1m\u001b[31mdestroyed\u001b[0m\n",
      "\u001b[0m  \u001b[31m-\u001b[0m\u001b[0m resource \"ec_elasticsearch_project\" \"demo_project\" {\n",
      "      \u001b[31m-\u001b[0m\u001b[0m alias         = \"demoproject\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m cloud_id      = \"demo_project:dXMtY2VudHJhbDEuZ2NwLmVsYXN0aWMuY2xvdWQkY2I1NDQ2MzMyYjI0NGU4YmE5M2UxYmIyNzRmNzY0YTguZXMkY2I1NDQ2MzMyYjI0NGU4YmE5M2UxYmIyNzRmNzY0YTgua2I=\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m credentials   = {\n",
      "          \u001b[31m-\u001b[0m\u001b[0m password = \"55SMgEkc34c92qSFd6s89a8o\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m\u001b[0m username = \"admin\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "        } \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m endpoints     = {\n",
      "          \u001b[31m-\u001b[0m\u001b[0m elasticsearch = \"https://demoproject-cb5446.es.us-central1.gcp.elastic.cloud\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m\u001b[0m kibana        = \"https://demoproject-cb5446.kb.us-central1.gcp.elastic.cloud\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "        } \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m id            = \"cb5446332b244e8ba93e1bb274f764a8\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m metadata      = {\n",
      "          \u001b[31m-\u001b[0m\u001b[0m created_at      = \"2025-12-07 14:28:28.929538265 +0000 UTC\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m\u001b[0m created_by      = \"3109974691\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m\u001b[0m organization_id = \"2698784787\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "        } \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m name          = \"demo_project\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m optimized_for = \"general_purpose\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m region_id     = \"gcp-us-central1\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m search_lake   = {\n",
      "          \u001b[31m-\u001b[0m\u001b[0m boost_window = 7 \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "          \u001b[31m-\u001b[0m\u001b[0m search_power = 2000 \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "        } \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "      \u001b[31m-\u001b[0m\u001b[0m type          = \"elasticsearch\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "    }\n",
      "\n",
      "\u001b[1mPlan:\u001b[0m \u001b[0m0 to add, 0 to change, 1 to destroy.\n",
      "\n",
      "Changes to Outputs:\n",
      "  \u001b[31m-\u001b[0m\u001b[0m elastic_cloud_id = \"demo_project:dXMtY2VudHJhbDEuZ2NwLmVsYXN0aWMuY2xvdWQkY2I1NDQ2MzMyYjI0NGU4YmE5M2UxYmIyNzRmNzY0YTguZXMkY2I1NDQ2MzMyYjI0NGU4YmE5M2UxYmIyNzRmNzY0YTgua2I=\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m\u001b[0m elastic_password = (sensitive value) \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m\u001b[0m elastic_username = \"admin\" \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m\u001b[0m gemini_api_key   = (sensitive value) \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "  \u001b[31m-\u001b[0m\u001b[0m jina_api_key     = (sensitive value) \u001b[90m-> null\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Destroying... [id=cb5446332b244e8ba93e1bb274f764a8]\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1mec_elasticsearch_project.demo_project: Destruction complete after 0s\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Destroy complete! Resources: 1 destroyed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "terraform -chdir=terraform destroy -auto-approve\n",
    "rm -f .env"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
